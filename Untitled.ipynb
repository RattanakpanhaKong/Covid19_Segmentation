{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55c11c9",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10769d-50c5-4a27-b37f-cd3e3e39dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f4d98",
   "metadata": {},
   "source": [
    " ## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b0561-b033-4f0c-9996-ea14c3bbe17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e639fc1",
   "metadata": {},
   "source": [
    "## Plot Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da83fb-5ea2-43eb-adc6-d8041d9a9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_masks(images, masks, filenames):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(num_images, 2, figsize=(10, 5 * num_images))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image, mask = images[i], masks[i]\n",
    "        image_filename, mask_filename = filenames[i]\n",
    "\n",
    "        axes[i, 0].imshow(image.squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title(f'Image: {image_filename}')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(mask.squeeze(), cmap='gray')\n",
    "        axes[i, 1].set_title(f'Mask: {mask_filename}')\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea440b3c",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72814150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset():\n",
    "    image_dir = 'data/train/image'  \n",
    "    mask_dir = 'data/train/mask'  \n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    dataset = XRayDataset(image_dir, mask_dir, transform)\n",
    "\n",
    "    # Number of samples to display\n",
    "    num_samples = 2\n",
    "    images, masks, filenames = [], [], []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image, mask = dataset[i]\n",
    "        image_filename = dataset.images[i]\n",
    "        mask_filename = dataset.images[i]\n",
    "        print(mask.shape)\n",
    "\n",
    "        images.append(image.numpy())\n",
    "        masks.append(mask.numpy())\n",
    "        filenames.append((image_filename, mask_filename))\n",
    "\n",
    "    plot_images_and_masks(images, masks, filenames)\n",
    "\n",
    "test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473ff9e",
   "metadata": {},
   "source": [
    "## Model - UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972f5b8-3184-4d57-ad1a-6064c84c6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\"\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "    \n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class DoubleConv(nn.Module):\n",
    "#     \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         self.double_conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.double_conv(x)\n",
    "\n",
    "\n",
    "# class Down(nn.Module):\n",
    "#     \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         self.maxpool_conv = nn.Sequential(\n",
    "#             nn.MaxPool2d(2),\n",
    "#             DoubleConv(in_channels, out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "# class Up(nn.Module):\n",
    "#     \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "#         if bilinear:\n",
    "#             self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "#         else:\n",
    "#             self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "#         self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         x1 = self.up(x1)\n",
    "#         # input is CHW\n",
    "#         diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "#         diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "#         x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "#                         diffY // 2, diffY - diffY // 2])\n",
    "#         # if you have padding issues, see\n",
    "#         # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "#         # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "#         x = torch.cat([x2, x1], dim=1)\n",
    "#         return self.conv(x)\n",
    "\n",
    "\n",
    "# class OutConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(OutConv, self).__init__()\n",
    "#         self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.conv(x)\n",
    "\n",
    "\n",
    "# \"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "#         super(UNet, self).__init__()\n",
    "#         self.n_channels = n_channels\n",
    "#         self.n_classes = n_classes\n",
    "#         self.bilinear = bilinear\n",
    "\n",
    "#         inter_channel = 16\n",
    "\n",
    "#         self.inc = DoubleConv(n_channels, inter_channel)\n",
    "#         self.down1 = Down(inter_channel, inter_channel*2)\n",
    "#         self.down2 = Down(inter_channel*2, inter_channel*4)\n",
    "#         self.down3 = Down(inter_channel*4, inter_channel*8)\n",
    "#         self.down4 = Down(inter_channel*8, inter_channel*8)\n",
    "#         self.up1 = Up(inter_channel*16, inter_channel*4, bilinear)\n",
    "#         self.up2 = Up(inter_channel*8, inter_channel*2, bilinear)\n",
    "#         self.up3 = Up(inter_channel*4, inter_channel, bilinear)\n",
    "#         self.up4 = Up(inter_channel*2, inter_channel, bilinear)\n",
    "#         self.outc = OutConv(inter_channel, n_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1 = self.inc(x)\n",
    "#         x2 = self.down1(x1)\n",
    "#         x3 = self.down2(x2)\n",
    "#         x4 = self.down3(x3)\n",
    "#         x5 = self.down4(x4) # 1/16\n",
    "#         x = self.up1(x5, x4)\n",
    "#         x = self.up2(x, x3)\n",
    "#         x = self.up3(x, x2)\n",
    "#         x = self.up4(x, x1)\n",
    "#         logits = self.outc(x)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     unet = UNet(n_channels=1, n_classes=2)\n",
    "#     aa = torch.ones((2, 1, 128, 128))\n",
    "#     bb = unet(aa)\n",
    "#     print (bb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c644a-5aeb-46f3-a556-6bbcd3740f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_unet():\n",
    "#     # Step 1: Instantiate the model\n",
    "#     model = UNET(1,1)\n",
    "\n",
    "#     # Step 2: Generate a sample input\n",
    "#     sample_input = torch.randn(1, 1, 256, 256)  # Batch size of 1, 1 channel, 256x256 image\n",
    "\n",
    "#     # Step 3: Forward pass\n",
    "#     output = model(sample_input)\n",
    "\n",
    "#     # Step 4: Check the output\n",
    "#     print(f\"Input shape: {sample_input.shape}\")\n",
    "#     print(f\"Output shape: {output.shape}\")\n",
    "#     assert output.shape == sample_input.shape, \"The output shape is incorrect!\"\n",
    "\n",
    "#     # Optionally visualize the input and output\n",
    "#     input_image = sample_input.squeeze().detach().numpy()\n",
    "#     output_image = output.squeeze().detach().numpy()\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "#     axes[0].imshow(input_image, cmap='gray')\n",
    "#     axes[0].set_title('Input Image')\n",
    "#     axes[0].axis('off')\n",
    "\n",
    "#     axes[1].imshow(output_image, cmap='gray')\n",
    "#     axes[1].set_title('Output Image')\n",
    "#     axes[1].axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# test_unet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02285720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        smooth = 1e-5\n",
    "\n",
    "        intersection = torch.sum(inputs * targets)\n",
    "        dice_coeff = (2. * intersection + smooth) / (torch.sum(inputs) + torch.sum(targets) + smooth)\n",
    "\n",
    "        return 1. - dice_coeff\n",
    "\n",
    "# def dice_coefficient(inputs, targets):\n",
    "#     smooth = 1e-5\n",
    "#     intersection = torch.sum(inputs * targets)\n",
    "#     dice = (2. * intersection + smooth) / (torch.sum(inputs) + torch.sum(targets) + smooth)\n",
    "#     return dice\n",
    "\n",
    "# class DiceLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DiceLoss, self).__init__()\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         dice = dice_coefficient(inputs, targets)\n",
    "#         return 1. - dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528157b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0cb28-92e0-4e49-a5f8-35a25a5735f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_image_dir, train_mask_dir, valid_image_dir, valid_mask_dir, epochs=10, batch_size=20, lr=1e-5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    train_dataset = XRayDataset(train_image_dir, train_mask_dir, transform=get_transforms())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    valid_dataset = XRayDataset(valid_image_dir, valid_mask_dir, transform=get_transforms())\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)  # Ensure no shuffling\n",
    "\n",
    "    model = UNet(1, 1).to(device)\n",
    "    # model = UNet(n_channels=1, n_classes=1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # criterion = DiceLoss()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    # sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    train_loss_values = []\n",
    "    valid_loss_values = []\n",
    "    valid_iou_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "\n",
    "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            # print(outputs)\n",
    "\n",
    "            # Ensure the dimensions match\n",
    "            outputs = F.interpolate(outputs, size=masks.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "            # Convert masks to float and ensure they are between 0 and 1\n",
    "            masks = masks.float() / 255.0\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            # Print loss each iteration\n",
    "            # print(f'Epoch {epoch + 1}, Iteration {batch_idx + 1}, Train Loss: {loss.item()}')\n",
    "\n",
    "        train_loss_values.append(epoch_train_loss / len(train_loader))\n",
    "        \n",
    "        # Print loss each epoch\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {epoch_train_loss / len(train_loader)}')\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()  # Evaluation mode\n",
    "        epoch_valid_loss = 0\n",
    "        epoch_valid_iou = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images_val, masks_val in valid_loader:\n",
    "                images_val, masks_val = images_val.to(device), masks_val.to(device)\n",
    "\n",
    "                outputs_val = model(images_val)\n",
    "                outputs_val = F.interpolate(outputs_val, size=masks_val.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "                masks_val = masks_val.float() / 255.0\n",
    "\n",
    "                valid_loss = criterion(outputs_val, masks_val)\n",
    "                epoch_valid_loss += valid_loss.item()\n",
    "\n",
    "                # Calculate Mean IoU using logits\n",
    "                iou = compute_mean_iou(outputs_val, masks_val)\n",
    "                # print(\"IOU = \", iou)\n",
    "                epoch_valid_iou += iou\n",
    "                \n",
    "        valid_loss_values.append(epoch_valid_loss / len(valid_loader))\n",
    "        valid_iou_values.append(epoch_valid_iou / len(valid_loader))\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Validation Loss: {epoch_valid_loss / len(valid_loader)}, Validation IoU: {epoch_valid_iou / len(valid_loader)}')\n",
    "        print(\"=====================================================================\")\n",
    "\n",
    "    torch.save(model.state_dict(), 'unet_model.pth')\n",
    "\n",
    "    # Plot the training and validation loss curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), train_loss_values, marker='o', label='Training Loss')\n",
    "    plt.plot(range(1, epochs + 1), valid_loss_values, marker='o', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), valid_iou_values, marker='o', label='Validation IoU')\n",
    "    plt.title('Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean IoU')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_mean_iou(outputs, masks):\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    outputs = sigmoid(outputs)  \n",
    "    predicted_masks = (outputs > 0.5).float()\n",
    "\n",
    "    intersection = torch.logical_and(predicted_masks, masks).sum().float()\n",
    "    union = torch.logical_or(predicted_masks, masks).sum().float() + 1e-10  # Avoid division by zero\n",
    "\n",
    "    iou = (intersection / union).mean()\n",
    "    return iou.item()\n",
    "\n",
    "# Example usage\n",
    "print(\"Start training\")\n",
    "train_model('data/train/image', 'data/train/mask', 'data/valid/image', 'data/valid/mask')\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e0aa9",
   "metadata": {},
   "source": [
    "## Test Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee9060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_prediction(model, image_path, mask_path, transform):\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    mask_tensor = transform(mask).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "\n",
    "    predicted_mask = (output > 0.5).float()\n",
    "\n",
    "\n",
    "    image_np = image_tensor.squeeze().cpu().numpy() \n",
    "    mask_np = mask_tensor.squeeze().cpu().numpy() \n",
    "    predicted_mask_np = predicted_mask.squeeze().cpu().numpy()\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = compute_iou(predicted_mask_np, mask_np)\n",
    "\n",
    "    # Visualize input image, ground truth mask, and predicted mask\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(image_np, cmap='gray')\n",
    "    axes[0].set_title('Input Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(mask_np) \n",
    "    axes[1].set_title('Ground Truth Mask')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(predicted_mask_np)\n",
    "    axes[2].set_title(f'Predicted Mask (IoU: {iou:.4f})')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return iou\n",
    "\n",
    "def compute_iou(predicted_mask, mask):\n",
    "    predicted_mask = predicted_mask > 0.5\n",
    "    mask = mask > 0.5\n",
    "\n",
    "    intersection = np.logical_and(predicted_mask, mask).sum()\n",
    "    union = np.logical_or(predicted_mask, mask).sum()\n",
    "\n",
    "    iou = intersection / (union + 1e-10)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def main():\n",
    "    image_path = 'data/test/image/covid_1579.png'\n",
    "    mask_path = 'data/test/mask/covid_1579.png'\n",
    "\n",
    "    # Obtain the transformation pipeline\n",
    "    transform = get_transforms()\n",
    "\n",
    "    # Load model and weights\n",
    "    model = UNet(n_channels=1, n_classes=1)\n",
    "    model.load_state_dict(torch.load('unet_model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # Test the model on a single image and mask\n",
    "    iou = test_model_prediction(model, image_path, mask_path, transform)\n",
    "    print(f\"IOU for the image: {iou:.4f}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
